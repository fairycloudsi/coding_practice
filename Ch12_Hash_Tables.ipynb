{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple hash table-based data structures commonly used in Python--set, dict, collections.defaultdict, and collections.Counter. The difference between set and the ohter three is that is set simply stores keys, whereas the ohters store key-value pairs. All have the property that they do not allow for duplicate keys, unlike, for example, list. \n",
    "\n",
    "In a dict, accessing value associated with a key that is not present lead to a KeyError exception. However, a collections.defaultdict returns the default value for the type that was specified when the collection was instantiated, e.g., if d = collections.defaultdict(list), then if k not in d then d[k] is []. A collections.Counter is used for counting the number of occurrences of keys, with a number of set-like operations, as illustrated below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'a': 4, 'b': 3})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = collections.Counter(a = 3, b =1)\n",
    "d = collections.Counter(a = 1, b = 2)\n",
    "# add two counters toghether: c[x] + d[x]\n",
    "c + d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'a': 2})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# substract (keeping only positive counts)\n",
    "c -  d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'a': 1, 'b': 1})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intersection: min(c[x], d[x])\n",
    "c & d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'a': 3, 'b': 2})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Union: max(c[x], d[x])\n",
    "c | d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [1,2,4,5,2,4,6,3,2]\n",
    "Aset = set(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4, 5, 6}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Aset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aset.add(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4, 5, 6, 9}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Aset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aset.remove(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4, 5, 9}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Aset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aset.discard(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4, 9}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Aset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "newset = {1,2,3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newset <= Aset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-58ca77e79dc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mAset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 6"
     ]
    }
   ],
   "source": [
    "Aset.remove(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aset.discard(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between remove() and discard() is remove() remove the element from the set if it not constained it raises a KeyError. On the other hand, discard() remove the element too if it is contained but if not contained does not raise any error. \n",
    "\n",
    "The basic operations on the three key-value collections are similar to those on set. One difference is with iterators-- iteration over a key-value collection yields the keys. To iterate over the key-value paris, iterave over items(); to iterate over values, uses values(). (The keys() method return iterator to the keys.)\n",
    "\n",
    "Not every type is \"hashable\", i.e., can be added to a set or used as a key in a dict. In particular, mutable containers are not hashable--this is to prevent a client from modifying an object after adding it to the container, since the lookup will then fail to find it if the slot that the modified object hashes to is difference. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.1 Test for Palindromic Permutations\n",
    "\n",
    "Write a program to test whether the letters forming a string can be permuted to form a palindrome. For example, \"edified\" can be permuted to form \"deified\".\n",
    "\n",
    "**Hint:** All characters must occur in pairs for a string to be permutable into a palindrome, with one exception, if the string is of odd length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def can_form_palindrome(s: str) -> bool:\n",
    "    # A string can be permuted to form a palindrome if and only if the number\n",
    "    # of chars whose frequencies is odd is at most 1.\n",
    "    return sum(v % 2 for v in collections.Counter(s).values()) <= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'loeloev'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "can_form_palindrome(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'loelooe'\n",
    "can_form_palindrome(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'loeloe'\n",
    "can_form_palindrome(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'loelov'\n",
    "can_form_palindrome(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_s = collections.Counter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'l': 2, 'o': 2, 'e': 1, 'v': 1})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([2, 2, 1, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash_s.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('l', 2), ('o', 2), ('e', 1), ('v', 1)])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash_s.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['l', 'o', 'e', 'v'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash_s.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "small_sum = 0 \n",
    "for v in hash_s.values():\n",
    "    small_sum += v %2 \n",
    "    print(small_sum )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time complexit is O(n), where n i sht elenght of the string. The space complexity is O(c), where c is the number of distinct characters appearing in the string. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.2 Is an Anonymous Letter Constructible?\n",
    "\n",
    "Write a program which takes text for an anonymous letter and text for a magazine and determines if it is possible to write the anonymouse letter using the magazine. The anonymous letter can be written using the magazine if for each character in the anonymous letter, the number of times it appears in the anonymous letter is no more than the number of times it appears in the magazine. \n",
    "\n",
    "**Hint:** Count the number of distince characters appearing in the letter. \n",
    "\n",
    "A better approach is to make a single pass over the letter, storing the character counts for the letter in a single hash table--keys are characters, and values are the number of times that character appears. Next, we make a pass over the magazine. When processing a character c, if c appears in the hash table, we reduce its count by 1; we remove it from the hash when its count goes to zero. If the hash becomes empty, we return true. If we reach the end of the magazine and the hash is empty, we return false--each of the characters remaining in the hash occurs more times in the letter than the magazine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_letter_constructible_from_magazine(letter_text: str, \n",
    "                                          magazine_text: str) -> bool:\n",
    "    # Compute the frequencies for all chars in letter_text\n",
    "    char_frequency_for_letter = collections.Counter(letter_text)\n",
    "    \n",
    "    # Checks if characters in magazine_text can cover characters in \n",
    "    # char_frequency_for_letter.\n",
    "    for c in magazine_text:\n",
    "        if c in char_frequency_for_letter:\n",
    "            char_frequency_for_letter[c] -= 1\n",
    "            if char_frequency_for_letter[c] == 0:\n",
    "                del char_frequency_for_letter[c]\n",
    "                if not char_frequency_for_letter:\n",
    "                    # All characters for letter_text are matched\n",
    "                    return True\n",
    "    \n",
    "    # Empty char_frequency_for_letter means every char in letter_text \n",
    "    # can be covered by a character in magazine_text\n",
    "    return not char_frequency_for_letter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_text = 'I went to school in Sunday'\n",
    "magazine_text = 'Sunday is so great Marry and I went to shopping instead of taking classes in school'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_letter_constructible_from_magazine(letter_text, magazine_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letter_text = 'I like singing'\n",
    "is_letter_constructible_from_magazine(letter_text, magazine_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letter_text = 'Brown like dancing'\n",
    "is_letter_constructible_from_magazine(letter_text, magazine_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'B': 1,\n",
       "         'r': 1,\n",
       "         'o': 1,\n",
       "         'w': 1,\n",
       "         'n': 3,\n",
       "         ' ': 2,\n",
       "         'l': 1,\n",
       "         'i': 2,\n",
       "         'k': 1,\n",
       "         'e': 1,\n",
       "         'd': 1,\n",
       "         'a': 1,\n",
       "         'c': 1,\n",
       "         'g': 1})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(letter_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'S': 1,\n",
       "         'u': 1,\n",
       "         'n': 7,\n",
       "         'd': 3,\n",
       "         'a': 7,\n",
       "         'y': 2,\n",
       "         ' ': 15,\n",
       "         'i': 5,\n",
       "         's': 8,\n",
       "         'o': 6,\n",
       "         'g': 3,\n",
       "         'r': 3,\n",
       "         'e': 4,\n",
       "         't': 5,\n",
       "         'M': 1,\n",
       "         'I': 1,\n",
       "         'w': 1,\n",
       "         'h': 2,\n",
       "         'p': 2,\n",
       "         'f': 1,\n",
       "         'k': 1,\n",
       "         'c': 2,\n",
       "         'l': 2})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(magazine_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'B': 1})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(letter_text) - collections.Counter(magazine_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pythonic solution that exploits collections.Counter. Note that the\n",
    "# substraction only keeps keys with positive counts. \n",
    "def is_letter_constructible_from_magazine_pythonic(letter_text, magazine_text):\n",
    "    return (not collections.Counter(letter_text) - collections.Counter(magazine_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_letter_constructible_from_magazine_pythonic(letter_text, magazine_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the worst-case, the letter is not constructible or the last character of the magazine is essentially required. Therefore, the time complexity is O(m+n) where m and n are the number of characters in the letter and magazine, respectively. The space complexity is the size of the hash table constructed in the pass over the letter, i.e., O(L), where L is the number of distinct characters appearing in the letter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.3 Implement an ISBN Cache\n",
    "\n",
    "The international Standard Book Number (ISBN) is a unique commercial book identifier. It is a string of length 10. The first 9 characters are digits; the last character is a check character. The check character is the sum of the first 9 digits, mod 11, with 10 represented by 'X'. \n",
    "\n",
    "Create a cache for looking up prices of books identified by their ISBN. For the purpose of this exercise, treat ISBNs and prices as positive integers. You must implement lookup, insert, and erase method. Use the Least Recently Used(LRU) policy for cache eviction. \n",
    "\n",
    "* Insert: If an ISBN is already present, insert should not update the price, but should update the ISBN to be the most recently used entry.\n",
    "* Lookup: given an ISBN, return the corresponding price; if the element is not present, return -1. If the ISBN is present, update the entry to be the most recently used ISBN. \n",
    "* Erase: remove the specified ISBN and corresponding value from the case. Return true is the ISBN was present; otherwise, return false. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sol:** Hash tables are ideally suited for fast lookups. We can use a hash table to quickly lookup price by using ISBNs as keys, and a counter, which we use to record when an operation was performed--every time we do an insert or a lookup we incremenet the counter. For each ISBN we store a value which is the price and the \"timestamp\", which is the count corresponding to when the ISBN was most recently inserted or looked-up. \n",
    "\n",
    "This approach has O(1) lookup and delete times. Inserts are O(1) time, until the cache is full. Once the cache fills up, to add a new ISBN we have to find the LRU ISBN, which will be evicted to make place for the new entry. Finding the entry takes O(n) time, where n is the cache size, since we have to scan all entries to find the one with the smallest timestamp. Therefore the time complexity of inserts is O(n). \n",
    "\n",
    "The way to imporve efficiency is to avoid processing all ISBNs. Conceptually, the ISBNs are ordered by when they were most recently used, and we only need to be able to find the oldest ISBN efficiently. This suggests recording the ISBNs in a queue (in addition to the hash table). \n",
    "\n",
    "Specifically, for each ISBN, we store a reference to its location in the queue. Each time we do a lookup on an ISBN, we move to the front of the queue. (This requires us to use a linked list implementation of the queue, so taht items in the middle of the queue can be moved to the head.) We do the same when we insert an ISBN that's already present. If an insert results in the queue size exceeding n, the ISBN at the tail of the queue is deleted from the cache, i.e., from the queue and the hash table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LruCache:\n",
    "    def __init__(self, capacity: int) -> None: \n",
    "        self._isbn_price_table = collections.OrderedDict()\n",
    "        self._capacity = capacity\n",
    "        \n",
    "    def lookup(self, isbn: int) -> int:\n",
    "        if isbn not in self._isbn_price_table:\n",
    "            return -1 \n",
    "        price = self._isbn_price_table.pop(isbn)\n",
    "        self._isbn_price_table[isbn] = price\n",
    "        return price \n",
    "    \n",
    "    def insert(self, isbn: int, price: int) -> None:\n",
    "        # We add the value for key only if key is not present -- we don't update \n",
    "        # existing value \n",
    "        if isbn in self._isbn_price_table:\n",
    "            price = self._isbn_price_table.pop(isbn)\n",
    "        elif len(self._isbn_price_table) == self._capacity:\n",
    "            self._isbn_price_table.popitem(last=False)\n",
    "        self._isbn_price_table[isbn] = price\n",
    "        \n",
    "    def erase(self, isbn: int) -> bool:\n",
    "        return self._isbn_price_table.pop(isbn, None) is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordered Dict in Python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a Dict:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"This is a Dict:\\n\")\n",
    "d = {}\n",
    "d['a'] = 1\n",
    "d['b'] = 2\n",
    "d['c'] = 3\n",
    "d['d'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 1\n",
      "b 2\n",
      "c 3\n",
      "d 4\n"
     ]
    }
   ],
   "source": [
    "for key,value in d.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an Ordered Dict: \n",
      "\n",
      "a 1\n",
      "b 2\n",
      "c 3\n",
      "d 4\n"
     ]
    }
   ],
   "source": [
    "print(\"This is an Ordered Dict: \\n\")\n",
    "od = OrderedDict()\n",
    "od['a'] = 1\n",
    "od['b'] = 2\n",
    "od['c'] = 3\n",
    "od['d'] = 4\n",
    "\n",
    "for key,value in od.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Key value Change: If the value of a certian key is changed, the position of the key remains unchanged in OrderedDict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: \n",
      "\n",
      "a 1\n",
      "b 2\n",
      "c 3\n",
      "d 4\n",
      "\n",
      " After:\n",
      "\n",
      "a 1\n",
      "b 2\n",
      "c 5\n",
      "d 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Before: \\n\")\n",
    "for key,value in od.items():\n",
    "    print(key, value)\n",
    "print(\"\\n After:\\n\")\n",
    "od['c'] = 5\n",
    "for key,value in od.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Deletion and Re-Inserting: Deeting and re-inserting the same key will push it to the back as OrderedDict however maintains the order of insertion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before deleting:\n",
      "\n",
      "a 1\n",
      "b 2\n",
      "c 5\n",
      "d 4\n",
      "\n",
      " After deleting: \n",
      "\n",
      "a 1\n",
      "b 2\n",
      "d 4\n",
      "\n",
      " After re-inserting: \n",
      "\n",
      "a 1\n",
      "b 2\n",
      "d 4\n",
      "c 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Before deleting:\\n\")\n",
    "\n",
    "for key, value in od.items():\n",
    "    print(key, value)\n",
    "    \n",
    "print(\"\\n After deleting: \\n\")\n",
    "od.pop('c')\n",
    "for key,value in od.items():\n",
    "    print(key, value)\n",
    "\n",
    "print(\"\\n After re-inserting: \\n\")\n",
    "od['c'] = 3\n",
    "for key, value in od.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('c', 3)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "od.popitem('c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 1\n",
      "b 2\n",
      "d 4\n"
     ]
    }
   ],
   "source": [
    "for key, value in od.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a', 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "od.popitem(last = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b 2\n",
      "d 4\n"
     ]
    }
   ],
   "source": [
    "for key,value in od.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b 2\n"
     ]
    }
   ],
   "source": [
    "od.popitem(last = True)\n",
    "for key, value in od.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "lalala_table = LruCache(capacity = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lalala_table._capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "lalala_table.insert(isbn = 123421332, price = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123421332 5\n"
     ]
    }
   ],
   "source": [
    "for isbn, price in lalala_table._isbn_price_table.items():\n",
    "    print(isbn, price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "lalala_table.insert(isbn = 123421333, price = 8)\n",
    "lalala_table.insert(isbn = 123421334, price = 2)\n",
    "lalala_table.insert(isbn = 123421335, price = 11)\n",
    "lalala_table.insert(isbn = 123421336, price = 3)\n",
    "lalala_table.insert(isbn = 123421337, price = 4)\n",
    "lalala_table.insert(isbn = 123421338, price = 12)\n",
    "lalala_table.insert(isbn = 123421339, price = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123421335 11\n",
      "123421336 3\n",
      "123421337 4\n",
      "123421338 12\n",
      "123421339 7\n"
     ]
    }
   ],
   "source": [
    "for isbn, price in lalala_table._isbn_price_table.items():\n",
    "    print(isbn, price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lalala_table.lookup(123421225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lalala_table.lookup(123421335)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123421336 3\n",
      "123421337 4\n",
      "123421338 12\n",
      "123421339 7\n",
      "123421335 11\n"
     ]
    }
   ],
   "source": [
    "for isbn, price in lalala_table._isbn_price_table.items():\n",
    "    print(isbn, price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lalala_table._isbn_price_table.pop(123421335)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123421336 3\n",
      "123421337 4\n",
      "123421338 12\n",
      "123421339 7\n"
     ]
    }
   ],
   "source": [
    "for isbn, price in lalala_table._isbn_price_table.items():\n",
    "    print(isbn, price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "lalala_table._isbn_price_table[123421335] = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123421336 3\n",
      "123421337 4\n",
      "123421338 12\n",
      "123421339 7\n",
      "123421335 11\n"
     ]
    }
   ],
   "source": [
    "for isbn, price in lalala_table._isbn_price_table.items():\n",
    "    print(isbn, price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lalala_table.erase(123421334)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lalala_table.erase(123421335)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123421336 3\n",
      "123421337 4\n",
      "123421338 12\n",
      "123421339 7\n"
     ]
    }
   ],
   "source": [
    "for isbn, price in lalala_table._isbn_price_table.items():\n",
    "    print(isbn, price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time complexity for each lookup is O(1) for the hash table lookup and O(1) for updating the queue, i.e. O(1) overall. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.4 Compute the LCA, Optimizing for Close Ancestors\n",
    "\n",
    "Design an algorithm for computing the LCA of wo nodes in a binary tree. The algorithm's time complexity should depend only on the distance from the nodes to the LCA. \n",
    "\n",
    "**Sol:** Intuitively, the brute-force approach is suboptimal because it potentially processes nodes well above the LCA. We can avoid this by alternating moving upwards from the two nodes and storing the nodes visited as we move up in a hash table.Each time we visit a node we check to see if it has been visited before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryTreeNode:\n",
    "    def __init__(self, data=None, left=None, right= None, parent = None, nexxt = None):\n",
    "        self.data = data\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.parent = parent\n",
    "        self.next = nexxt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lca(node0: BinaryTreeNode,\n",
    "        node1: BinaryTreeNode) -> BinaryTreeNode:\n",
    "    iter0, iter1 = node0, node1\n",
    "    nodes_on_path_to_root = set()\n",
    "    while iter0 or iter1:\n",
    "        # Ascend tree in tandem for these two nodes.\n",
    "        if iter0:\n",
    "            if iter0 in nodes_on_path_to_root:\n",
    "                return iter0\n",
    "            print('the traversal point of iter0')\n",
    "            print(tree_traversal_inorder(iter0))\n",
    "            nodes_on_path_to_root.add(iter0)\n",
    "            iter0 = iter0.parent\n",
    "        if iter1:\n",
    "            if iter1 in nodes_on_path_to_root:\n",
    "                return iter1 \n",
    "            print('the traversal point of iter1')\n",
    "            print(tree_traversal_inorder(iter1))\n",
    "            nodes_on_path_to_root.add(iter1)\n",
    "            iter1 = iter1.parent\n",
    "    raise ValueError('node0 and node1 are not in the same tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "node1 = BinaryTreeNode(314)\n",
    "node2 = BinaryTreeNode(6)\n",
    "node3 = BinaryTreeNode(6)\n",
    "node4 = BinaryTreeNode(271)\n",
    "node5 = BinaryTreeNode(561)\n",
    "node6 = BinaryTreeNode(2)\n",
    "node7 = BinaryTreeNode(271)\n",
    "node8 = BinaryTreeNode(28)\n",
    "node9 = BinaryTreeNode(0)\n",
    "node10 = BinaryTreeNode(3)\n",
    "node11 = BinaryTreeNode(1)\n",
    "node12 = BinaryTreeNode(28)\n",
    "node13 = BinaryTreeNode(17)\n",
    "node14 = BinaryTreeNode(401)\n",
    "node15 = BinaryTreeNode(257)\n",
    "node16 = BinaryTreeNode(641)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "node1.left = node2\n",
    "node1.right = node3\n",
    "node2.left = node4\n",
    "node2.right = node5\n",
    "node3.left = node6\n",
    "node3.right = node7\n",
    "node4.left = node8\n",
    "node4.right = node9\n",
    "node5.right = node10\n",
    "node10.left = node13\n",
    "node6.right = node11\n",
    "node11.left = node14\n",
    "node11.right = node15\n",
    "node14.right = node16\n",
    "node7.right = node12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "node2.parent = node1\n",
    "node3.parent = node1\n",
    "node4.parent = node2\n",
    "node5.parent = node2\n",
    "node6.parent = node3\n",
    "node7.parent = node3\n",
    "node8.parent = node4\n",
    "node9.parent = node4\n",
    "node10.parent = node5\n",
    "node13.parent = node10\n",
    "node11.parent = node6\n",
    "node14.parent = node11\n",
    "node15.parent = node11\n",
    "node16.parent = node14\n",
    "node12.parent = node7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_traversal_inorder(root: BinaryTreeNode) -> None:\n",
    "    if root:\n",
    "        tree_traversal_inorder(root.left) \n",
    "        print('Inorder: %d' % root.data)\n",
    "        tree_traversal_inorder(root.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inorder: 28\n",
      "Inorder: 271\n",
      "Inorder: 0\n",
      "Inorder: 6\n",
      "Inorder: 561\n",
      "Inorder: 17\n",
      "Inorder: 3\n",
      "Inorder: 314\n",
      "Inorder: 2\n",
      "Inorder: 401\n",
      "Inorder: 641\n",
      "Inorder: 1\n",
      "Inorder: 257\n",
      "Inorder: 6\n",
      "Inorder: 271\n",
      "Inorder: 28\n"
     ]
    }
   ],
   "source": [
    "tree_traversal_inorder(node1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the traversal point of iter0\n",
      "Inorder: 401\n",
      "Inorder: 641\n",
      "None\n",
      "the traversal point of iter1\n",
      "Inorder: 28\n",
      "None\n",
      "the traversal point of iter0\n",
      "Inorder: 401\n",
      "Inorder: 641\n",
      "Inorder: 1\n",
      "Inorder: 257\n",
      "None\n",
      "the traversal point of iter1\n",
      "Inorder: 271\n",
      "Inorder: 28\n",
      "None\n",
      "the traversal point of iter0\n",
      "Inorder: 2\n",
      "Inorder: 401\n",
      "Inorder: 641\n",
      "Inorder: 1\n",
      "Inorder: 257\n",
      "None\n",
      "the traversal point of iter1\n",
      "Inorder: 2\n",
      "Inorder: 401\n",
      "Inorder: 641\n",
      "Inorder: 1\n",
      "Inorder: 257\n",
      "Inorder: 6\n",
      "Inorder: 271\n",
      "Inorder: 28\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.BinaryTreeNode at 0x10d47cb00>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lca(node14, node12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inorder: 401\n",
      "Inorder: 641\n",
      "Inorder: 1\n",
      "Inorder: 257\n"
     ]
    }
   ],
   "source": [
    "tree_traversal_inorder(lca(node14, node15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we are trading space for tie. The algorithm for Solution 9.4 on Page 125 used O(1) space and O(h) time, whereas the algorithm presented above uses O(D0 + D1) space and time, where D0 is the distance from the LCA to the first node, and D1 is the distance from the LCA to the second node. In the worst-case, the nodes are leaves whose LCA is the root, and we end up using O(h) space and time, where h is the height of the tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.5 Find the Nearest Repeated Entries in an Array\n",
    "\n",
    "Peopel do not like reading text in which a word is used multiple imes in a short paragraph. You are to write a program which helps identify such a problem. \n",
    "\n",
    "Write a program which takes as input an array and finds the distance between a closet pair of equal entries. For example, if s = <\"All\", \"work\", \"and\", \"no\", \"play\", \"makes\", \"for\", \"no\", \"work\", \"no\", \"fun\", \"and\", \"no\", \"results\">, then the second and third occurrences of \"no\" is the closest pair. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sol:** The brute-force approach is to iterate over all pairs of entries, check if they are the same, and if so, if the distance between them is less than the smallest such distance seen so far. The time complexity is O(n^2), where n is the array length. \n",
    "\n",
    "We can improve upon the brute-force algorithm by nothing that when examining an entry, we do not need to look at every other entry--we only care about entries which are the same. We can store the set of indices corresponding to a given value using a hash table and iterate over all such sets. However, there is a better approach-- when processing an entry, all we care about is the closest previous equal entry. Specifically, as we scan through the array, for each vaue seen so far, we store in a hash tabe and latest index at which it appreas. When processing the lement, we use the hash table to see the latest index less than the current index holding the same value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_repetition(paragraph: list) -> int:\n",
    "    word_to_latest_index = {}\n",
    "    nearest_repreated_distance = float('inf')\n",
    "    for i, word in enumerate(paragraph):\n",
    "        if word in word_to_latest_index:\n",
    "            latest_equal_word = word_to_latest_index[word]\n",
    "            nearest_repreated_distance = min(nearest_repreated_distance, i- latest_equal_word)\n",
    "        \n",
    "        word_to_latest_index[word] = i\n",
    "    return typing.cast(int, nearest_repreated_distance\n",
    "                      ) if nearest_repreated_distance != float('inf') else -1 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph = ['All', 'work', 'and', 'no', 'play', 'makes', 'for', 'no', 'work',\n",
    "            'no', 'fun', 'and', 'no', 'results']\n",
    "find_nearest_repetition(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = ['wow', 'such' ,'a' ,'wonderful' ,'day', 'wow', 'so', 'so']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_nearest_repetition(paragraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time complexity is O(n), since we perform a constant amount of work per entry. The space complexity is O(d), where d is the number of distinct entries in the array. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.6 Find the Smallest Subarray Covering All Values \n",
    "\n",
    "When you type keywords in a search engine, the search engine will return results, and each result contains a digest of the web page, i.e., a hightlighting within that page of keywords that you searched for. For example, a seasrch for the keywords: \"Unions\" and \"save\" on a page with the test of the Emancipation Proclammation should return the result shown in Figure 12.1. \n",
    "\n",
    "The digest for this page is the text in boldface, with the keywords underlined for emphasis. It is the shortest substring of the page which contains all the keywords in the search. The problem of computing the digest is abstracted as follows. \n",
    "\n",
    "Write a program which takes an array of strings and a set of strings, and return the indices of the starting and ending index of a shortest subarray of the given array that \"covers\" the set, i.e., contains all strings in the set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sol:** We can further improve the algorithm by noting that when we move from i to i+1 we can reuse the work performed from i. Specifically, let's say the smallest sunarray starting at i coverint the set ends at j. There is no point in considering subarrays starting at i+1 and ending before j, since we know they cannot cover the set. When we advance to i+1, either we still cover the set, or we have to advance j to cover the set. We continously advance one of i or j, which implies an O(n) time complexity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subarray = collections.namedtuple('Subarray', ('start', 'end'))\n",
    "\n",
    "def find_smallest_subarray_covering_set(paragraph: list, keywords: set) -> Subarray:\n",
    "    keywords_to_cover = collections.Counter(keywords)\n",
    "    result = Subarray(-1, -1)\n",
    "    remaining_to_cover = len(keywords)\n",
    "    left = 0\n",
    "    for right, p in enumerate(paragraph):\n",
    "        if p in keywords:\n",
    "            keywords_to_cover[p] -= 1\n",
    "            if keywords_to_cover[p] >= 0:\n",
    "                remaining_to_cover -= 1\n",
    "                \n",
    "        \n",
    "        # Keeps advancing left until keywords_to_cover does not contain all keywords.\n",
    "        while remaining_to_cover == 0:\n",
    "            if result == (-1,-1) or right - left < result[1] - result[0]:\n",
    "                result = Subarray(left, right)\n",
    "            pl = paragraph[left]\n",
    "            if pl in keywords:\n",
    "                keywords_to_cover[pl] += 1\n",
    "                if keywords_to_cover[pl] > 0:\n",
    "                    remaining_to_cover += 1\n",
    "            left += 1\n",
    "    return result \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subarray(start=8, end=10)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph = ['apple', 'banana','apple','apple','dog','cat','apple','dog','banana','apple','cat','dog']\n",
    "\n",
    "keywords = {'banana', 'cat'}\n",
    "\n",
    "find_smallest_subarray_covering_set(paragraph, keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_to_cover = collections.Counter(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'banana': 1, 'cat': 1})\n"
     ]
    }
   ],
   "source": [
    "print(keywords_to_cover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = Subarray(-1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "remaining_to_cover = len(keywords)\n",
    "print(remaining_to_cover)\n",
    "left = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'cat': 1, 'banana': 0})\n",
      "1\n",
      "0\n",
      "1\n",
      "Counter({'banana': 1, 'cat': 0})\n",
      "1\n",
      "2\n",
      "5\n",
      "Counter({'cat': 1, 'banana': 0})\n",
      "1\n",
      "6\n",
      "8\n",
      "Counter({'banana': 1, 'cat': 0})\n",
      "1\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for right, p in enumerate(paragraph):\n",
    "    if p in keywords:\n",
    "        keywords_to_cover[p] -= 1\n",
    "        if keywords_to_cover[p] >= 0:\n",
    "            remaining_to_cover -= 1\n",
    "        # Keeps advancing left until keywords_to_cover does not contain all keywords\n",
    "        while remaining_to_cover == 0:\n",
    "            if result == (-1, -1) or right-left < result[1] - result[0]:\n",
    "                result = Subarray(left, right)\n",
    "            pl = paragraph[left]\n",
    "            if pl in keywords:\n",
    "                keywords_to_cover[pl] += 1 \n",
    "                if keywords_to_cover[pl] > 0:\n",
    "                    remaining_to_cover += 1\n",
    "            left += 1\n",
    "        print(keywords_to_cover)\n",
    "        print(remaining_to_cover)\n",
    "        print(left)\n",
    "        print(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subarray(start=8, end=10)\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complexity is O(n), where n is the length of the array, since for each of the two indices we spend O(1) time per advance, and each is advanced at most n-1 times. \n",
    "\n",
    "The disadvantage of this approach is that we need to keep the subarrays in memory. We can achieve a streaming algorithm by keeping track of latest occurrences of query keywords as we process A. We use a doubly linked list L to store the last occurrence (index) of each keyword in Q, and hash table H to map each keyword in Q to the corresponding node in L. Each time a word in Q is encountered, we remove its node from L(which we find by using H), create a new node which records the current index in A, and append the new node to the end of L. We also update H. By doing this, each keyword in L is ordered by its order in A; therefore, if L has n_Q words (i.e. all keywords are shown) and the current index minus the index stored in the first node in L is less than current best, we update current best. The complexity is O(n). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoublyLinkedListNode:\n",
    "    def __init__(self, data = None):\n",
    "        self.data = data\n",
    "        self.next = self.prev = None\n",
    "\n",
    "class LinkedList:\n",
    "    def __init__(self):\n",
    "        self.head = self.tail = None\n",
    "        self._size = 0\n",
    "    def __len__(self):\n",
    "        return self._size\n",
    "    def insert_after(self, value):\n",
    "        node = DoublyLinkedListNode(value)\n",
    "        node.prev = self.tail\n",
    "        if self.tail:\n",
    "            self.tail.next = node\n",
    "        else:\n",
    "            self.head = node\n",
    "        self.tail = node\n",
    "        self._size += 1\n",
    "    \n",
    "    def remove(self, node):\n",
    "        if node.next:\n",
    "            node.next.prev = node.prev \n",
    "        else:\n",
    "            self.tail = node.prev\n",
    "        if node.prev:\n",
    "            node.prev.next = node.next\n",
    "        else:\n",
    "            self.head = node.next\n",
    "        node.next = node.prev = None\n",
    "        self._size -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ListNode(L:DoublyLinkedListNode) -> None:\n",
    "    while L:\n",
    "        print(L.data) if L.data else print('no number')\n",
    "        L = L.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_smallest_subarray_covering_set_2(paragraph, keyworods: list) -> Subarray:\n",
    "    loc = LinkedList()\n",
    "    d = {s: None for s in keywords}\n",
    "    result = Subarray(-1, -1)\n",
    "    for idx, s in enumerate(paragraph):\n",
    "        if s in d: # s is in keywords\n",
    "            it = d[s]\n",
    "            if it is not None:\n",
    "                # Explicitly remove s so that when we add it, it's the string most \n",
    "                # frequently added to loc.\n",
    "                loc.remove(it)\n",
    "            loc.insert_after(idx)\n",
    "            d[s] = loc.tail\n",
    "            print_ListNode(loc.head)\n",
    "            \n",
    "            if len(loc) == len(keywords):\n",
    "                # We have seen all strings in keywords, let's get to work. \n",
    "                if (result == (-1, -1)\n",
    "                       or idx - loc.head.data < result[1] - result[0]):\n",
    "                    result = Subarray(loc.head.data, idx)\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "5\n",
      "5\n",
      "8\n",
      "8\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Subarray(start=8, end=10)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_smallest_subarray_covering_set_2(paragraph, keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.7 Find the Smallest Subarray Sequentially Covering All Values \n",
    "\n",
    "Write a program that takes two arrays of strings, and return the indices of the starting and ending index of a shortest subarray of the first array (the \"paragraph\" array) that \"sequentially covers\", i.e., contains all the strings in the second array (the \"keywords\" array), in the order in which they appear in the keywords array. You can assume all keywords are distinct. For example, let the paragraph array be <apple, banana, cat, apple>, and the keywords array be <banana, apple> . The paragraph subarray starting at index 0 and ending at index 1 doest not fulfill the specification, even though it contains all the keywords, since they do not appear in the specified order. On the other hand, the subarray starting at index 1 and ending at index 3 does fulfill the specification.\n",
    "\n",
    "**Hint:** For each index in the paragraph array, compute the shortest subarray ending at that index which fulfills the specification. \n",
    "\n",
    "**Sol:** Specifically, we use a hash table to map keywords to their most recent occurrences in the paragraph array as we iterate through it, and a hash table mapping each keyword to the length of the shortest subarray ending at the most recent occurrence of that keyword. \n",
    "\n",
    "These two hash tables give us is the ability to determine the shortest subarray sequentially covering the first k keywords given the shortest subarray sequentially covering the first k-1 keywords. \n",
    "\n",
    "When processing the ith string in the paragraog array, if that string is the jth keyword, we update the most recent occurrence of that keyword to i. The shortest subarray ending at i which sequentially covers the first j keywords consists of the shortest subarray ending at the most recent occurrence of the first j -1 keywords plus the lements from the most recent occurrence of the (j-1) th keyword to i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subarray = collections.namedtuple('Subarray', ('start', 'end'))\n",
    "\n",
    "def find_smallest_sequentially_covering_subset(\n",
    "    paragraph: list, keywords: list) -> Subarray:\n",
    "    # Maps each keyword to its index in the keywords array.\n",
    "    keyword_to_idx = {k : i for i,k in enumerate(keywords)}\n",
    "    \n",
    "    # Since keywords are uniquely identified by their indices in keywords arrays, \n",
    "    # we can use those indices as keys to lookup in an array.\n",
    "    latest_occurrence = [-1]* len(keywords)\n",
    "    # For each keyword (identified by its index in keywords array), the length\n",
    "    # of the shortest subarray ending at the most recent occurrence of that \n",
    "    # keyword that squentially cover all keywords up to that keyword. \n",
    "    shortest_subarray_length = [float('inf')] * len(keywords)\n",
    "    \n",
    "    shortest_distance = float('inf')\n",
    "    result = Subarray(-1, -1)\n",
    "    for i, p in enumerate(paragraph):\n",
    "        if p in keyword_to_idx:\n",
    "            keyword_idx = keyword_to_idx[p]\n",
    "            if keyword_idx == 0: # First keyword.\n",
    "                shortest_subarray_length[keyword_idx] = 1\n",
    "            elif shortest_subarray_length[keyword_idx - 1] != float('inf'):\n",
    "                distance_to_previous_keyword = (\n",
    "                    i - latest_occurrence[keyword_idx - 1])\n",
    "                shortest_subarray_length[keyword_idx] = (\n",
    "                    distance_to_previous_keyword + \n",
    "                    shortest_subarray_length[keyword_idx - 1])\n",
    "            latest_occurrence[keyword_idx] = 1\n",
    "            \n",
    "            # Last keyword, for improved subarray.\n",
    "            if (keyword_idx == len(keywords) - 1\n",
    "                   and shortest_subarray_length[-1] < shortest_distance):\n",
    "                shortest_distance = shortest_subarray_length[-1]\n",
    "                result = Subarray(i - shortest_distance + 1, i)\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'banana', 'apple', 'apple', 'dog', 'cat', 'apple', 'dog', 'banana', 'apple', 'cat', 'dog']\n"
     ]
    }
   ],
   "source": [
    "print(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'banana', 'cat'}\n"
     ]
    }
   ],
   "source": [
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subarray(start=1, end=6)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = ['dog', 'apple']\n",
    "find_smallest_sequentially_covering_subset(paragraph, keywords )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dog': 0, 'apple': 1}\n"
     ]
    }
   ],
   "source": [
    "keyword_to_idx = {k : i for i, k in enumerate(keywords)} # maps each keyword to its index in the keyword array\n",
    "print(keyword_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_occurrence = [-1]*len(keywords) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each keyword (identified by its index in keywords array), the length of the shortest subarray ending \n",
    "# at the most recent occurrence of that keyword that sequentially cover all keywords up to that keyword \n",
    "shortest_subarray_length = [float('inf') * len(keywords)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortest_distance = float('inf')\n",
    "result = Subarray(-1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 apple\n",
      "[inf]\n",
      "[-1, 0]\n",
      "Subarray(start=-1, end=-1)\n",
      "1 banana\n",
      "[inf]\n",
      "[-1, 0]\n",
      "Subarray(start=-1, end=-1)\n",
      "2 apple\n",
      "[inf]\n",
      "[-1, 2]\n",
      "Subarray(start=-1, end=-1)\n",
      "3 apple\n",
      "[inf]\n",
      "[-1, 3]\n",
      "Subarray(start=-1, end=-1)\n",
      "4 dog\n",
      "[1]\n",
      "[4, 3]\n",
      "Subarray(start=-1, end=-1)\n",
      "5 cat\n",
      "[1]\n",
      "[4, 3]\n",
      "Subarray(start=-1, end=-1)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-201ea7a9ebf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m             shortest_subarray_length[keyword_idx] = (\n\u001b[1;32m     10\u001b[0m                 \u001b[0mdistance_to_previous_keyword\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                 shortest_subarray_length[keyword_idx -1])\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mlatest_occurrence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeyword_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "for i, p in enumerate(paragraph):\n",
    "    if p in keyword_to_idx:\n",
    "        keyword_idx = keyword_to_idx[p]\n",
    "        if keyword_idx == 0: # First keyword. \n",
    "            shortest_subarray_length[keyword_idx] = 1\n",
    "        elif shortest_subarray_length[keyword_idx - 1] != float('inf'):\n",
    "            distance_to_previous_keyword = (\n",
    "                i - latest_occurrence[keyword_idx - 1])\n",
    "            shortest_subarray_length[keyword_idx] = (\n",
    "                distance_to_previous_keyword + \n",
    "                shortest_subarray_length[keyword_idx -1])\n",
    "        latest_occurrence[keyword_idx] = i\n",
    "        \n",
    "        # Latest keyword, for improved subarray.\n",
    "        if(keyword_idx == len(keywords) - 1\n",
    "              and shortest_subarray_length[-1] < shortest_distance):\n",
    "            shortest_distance = shortest_subarray_length[-1]\n",
    "            result = Subarray(i - shortest_distance + 1, i)\n",
    "    print(i,p)\n",
    "    print(shortest_subarray_length)\n",
    "    print(latest_occurrence)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.8 Find the Longest Subarray with Distinct Entries \n",
    "\n",
    "Write a program that takes an array and returns the length of a logest subarray with the property that all its elements are distinct. For example, if the array is <f,s,f,e,t,w,e,n,w,e> then a logest subarray all of whose elements are distinct is <s,f,e,t,w>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sol:** We can improve the time complexity by reusing previous computation as we iterate through the array. Suppose we know the longest duplicate-free subarray ending at a given index. The longest duplicate-free subarray ending at the next index is either the previous subarray appended with the element at the next index, if that element does not appear in the longest duplicate-free subarray at the current index. Otherwise it is the subarray beginning at the most recent occurrence of the element at the next index to the next index. To perform this case analysis as we iterate, all we need is a hash table storing the most recent occurrence of each element, and the longest duplicate-free subarray ending at the current element. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_subarray_with_distinct_entries(A : list)-> int:\n",
    "    # Record the most recent occurrences of each entry\n",
    "    most_recent_occurrence = {}\n",
    "    longest_dup_free_subarray_start_idx = result = 0\n",
    "    for i, a in enumerate(A):\n",
    "        # Defer updating dup_idx until we see a duplicate \n",
    "        if a in most_recent_occurrence:\n",
    "            dup_idx = most_recent_occurrence[a]\n",
    "            # A[i] appeared before. Did it appear in the longest current subarray?\n",
    "            if dup_idx >= longest_dup_free_subarray_start_idx:\n",
    "                result = max(result, i - longest_dup_free_subarray_start_idx)\n",
    "                longest_dup_free_subarray_start_idx = dup_idx + 1\n",
    "        most_recent_occurrence[a] = i\n",
    "        print('number of iteration')\n",
    "        print(i)\n",
    "        print(a)\n",
    "        print(most_recent_occurrence)\n",
    "        print(longest_dup_free_subarray_start_idx)\n",
    "    return max(result, len(A) - longest_dup_free_subarray_start_idx)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of iteration\n",
      "0\n",
      "f\n",
      "{'f': 0}\n",
      "0\n",
      "number of iteration\n",
      "1\n",
      "s\n",
      "{'f': 0, 's': 1}\n",
      "0\n",
      "number of iteration\n",
      "2\n",
      "f\n",
      "{'f': 2, 's': 1}\n",
      "1\n",
      "number of iteration\n",
      "3\n",
      "e\n",
      "{'f': 2, 's': 1, 'e': 3}\n",
      "1\n",
      "number of iteration\n",
      "4\n",
      "t\n",
      "{'f': 2, 's': 1, 'e': 3, 't': 4}\n",
      "1\n",
      "number of iteration\n",
      "5\n",
      "w\n",
      "{'f': 2, 's': 1, 'e': 3, 't': 4, 'w': 5}\n",
      "1\n",
      "number of iteration\n",
      "6\n",
      "e\n",
      "{'f': 2, 's': 1, 'e': 6, 't': 4, 'w': 5}\n",
      "4\n",
      "number of iteration\n",
      "7\n",
      "n\n",
      "{'f': 2, 's': 1, 'e': 6, 't': 4, 'w': 5, 'n': 7}\n",
      "4\n",
      "number of iteration\n",
      "8\n",
      "w\n",
      "{'f': 2, 's': 1, 'e': 6, 't': 4, 'w': 8, 'n': 7}\n",
      "6\n",
      "number of iteration\n",
      "9\n",
      "e\n",
      "{'f': 2, 's': 1, 'e': 9, 't': 4, 'w': 8, 'n': 7}\n",
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = ['f','s','f','e','t','w','e','n','w','e']\n",
    "longest_subarray_with_distinct_entries(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time complexity is O(n) since we perform a constant number of operations per element. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.9 Find the Length of a Longest Contained Interval \n",
    "\n",
    "Write a program which takes as input a set of integers represented by an array, and returns the size of a largest subset of integers in the array having the property that if two integers are in the subset, then so are all integers between them. For example, if the input is <3, -2, 7, 9, 8, 1, 2, 0, -1, 5, 8>, the largest such subset is {-2, -1, 0, 1, 2, 3}, so you should return 6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_contained_range(A: list) -> int:\n",
    "    # unprocessed_entries frecords the existence of each entry in A.\n",
    "    unprocessed_entries = set(A)\n",
    "    \n",
    "    max_interval_size = 0\n",
    "    while unprocessed_entries:\n",
    "        a = unprocessed_entries.pop()\n",
    "        print(a)\n",
    "        \n",
    "        # Finds the lower bound of the largest range containing a.\n",
    "        lower_bound = a - 1\n",
    "        while lower_bound in unprocessed_entries:\n",
    "            unprocessed_entries.remove(lower_bound)\n",
    "            lower_bound -= 1\n",
    "            print('lower_bound')\n",
    "            print(lower_bound)\n",
    "        \n",
    "        # Finds the upper bound of the largest range containing a.\n",
    "        upper_bound = a + 1\n",
    "        while upper_bound in unprocessed_entries:\n",
    "            unprocessed_entries.remove(upper_bound)\n",
    "            upper_bound += 1\n",
    "            print('upper_bound')\n",
    "            print(upper_bound)\n",
    "            \n",
    "        max_interval_size = max(max_interval_size,\n",
    "                               upper_bound - lower_bound - 1)\n",
    "        \n",
    "    return max_interval_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "upper_bound\n",
      "5\n",
      "upper_bound\n",
      "6\n",
      "upper_bound\n",
      "7\n",
      "100\n",
      "10\n",
      "upper_bound\n",
      "12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = [10,5,3,11,6,100,4]\n",
    "longest_contained_range(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.10 Compute All String Decompositions\n",
    "\n",
    "This problem is concerned with taking a string (the \"sentence\" string) and a set of strings (the \"words\"), and finding the substrings of the sentence which are the concatenation of all the words (in any order). For example, if the sentence string is \"amanaplanacanal\" and the set of words is {\"can\", \"apl\", \"ana\"}, \"aplanacan\" is a substring of the sentence that is the concatenation of all words. \n",
    "\n",
    "Write a program which takes as input a string (the \"sentence\") and an array of strings (the \"words\"), and returns the starting indices of substrings of the sentence string which are the concatenation of all the strings in the words array. Each string must appear exactly once, and their ordering is immaterial. Assume all strings in the words array have equal length. It is possible for the words array to contain duplicates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_substrings(s: str, words: list) -> list:\n",
    "    def match_all_words_in_dict(start):\n",
    "        curr_string_to_freq = collections.Counter()\n",
    "        for i in range(start, start + len(words) * unit_size, unit_size):\n",
    "            curr_word = s[i: i+ unit_size]\n",
    "            it = word_to_freq[curr_word]\n",
    "            if it == 0:\n",
    "                return False\n",
    "            curr_string_to_freq[curr_word] += 1\n",
    "            if curr_string_to_freq[curr_word] > it:\n",
    "                # curr_word occurs too may times for a match to be possible\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    word_to_freq = collections.Counter(words)\n",
    "    unit_size = len(words[0])\n",
    "    return [\n",
    "        i for i in range(len(s) - unit_size * len(words) + 1)\n",
    "        if match_all_words_in_dict(i)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'amanaplanacanal'\n",
    "words = [\"can\", \"apl\", \"ana\"]\n",
    "find_all_substrings(s, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
